{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader \n",
    "# from model import CNN_Model\n",
    "import torch.optim as optim \n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Cat_and_Dog_Classification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Cat_and_Dog_Classification, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,  out_channels=32,  kernel_size=3,  stride=1,  padding=0)   # (img_dim - kernel_size + 2*padding)//stride +  1  ===>  (224 - 3 + 2(0) )/2 +1  = 111.5 (out_1)  .. # out_1 / pooling = 111//2 = 55                                                                                                 \n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64,  kernel_size=3,  stride=1,  padding=0)   # (55   - kernel_size + 2*padding)//stride +  1  ===>  (55 - 3 + 2(0))/2 +1  = 27  (out_1)   .... # out_1 / pooling = 27//2 = 13                                         \n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64,  kernel_size=3,  stride=1,  padding=0)   # (13   - kernel_size + 2*padding)//stride +  1  ===>  (13 - 3 + 2(0))/2 +1  = 6  (out_1)\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(64*25*25, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1( F.relu( self.conv1(x) ))\n",
    "        x = self.pool1( F.relu( self.conv2(x) ))\n",
    "        x = self.pool1( F.relu( self.conv3(x) ))\n",
    "\n",
    "        # print(x.shape)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = transforms.Compose([ transforms.Grayscale(),\n",
    "                                        transforms.Resize((224, 224)), \n",
    "                                        transforms.RandomHorizontalFlip(p=0.4), \n",
    "                                        transforms.RandomRotation(30), \n",
    "                                        transforms.ToTensor(), \n",
    "                                        transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "                                      ])\n",
    "\n",
    "transforms_test  = transforms.Compose([ transforms.Grayscale(), \n",
    "                                        transforms.Resize((224, 224)), \n",
    "                                        transforms.ToTensor(), \n",
    "                                        transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "                                      ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets from Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/zorve/OneDrive/Documents/github datasets/cat_vs_dog/\"\n",
    "\n",
    "datasets_train = datasets.ImageFolder(root= path + 'train', transform=transforms_train)\n",
    "datasets_test  = datasets.ImageFolder(root= path + 'test',  transform=transforms_test) \n",
    "\n",
    "dataloader_train = DataLoader(dataset=datasets_train, batch_size=32, shuffle=True)\n",
    "dataloader_test  = DataLoader(dataset=datasets_test,  batch_size=32, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Model, Loss Function, and Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "\n",
    "model = CNN_Cat_and_Dog_Classification()\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/10 :  Train Loss : 0.692618  |  Test Loss : 0.690938  | Accuracy : 0.513542   |  Another Accuracy : 1.510000\n",
      "  2/10 :  Train Loss : 0.691006  |  Test Loss : 0.689110  | Accuracy : 0.536458   |  Another Accuracy : 1.550000\n",
      "  3/10 :  Train Loss : 0.684792  |  Test Loss : 0.693225  | Accuracy : 0.564583   |  Another Accuracy : 1.690000\n",
      "  4/10 :  Train Loss : 0.674336  |  Test Loss : 0.681766  | Accuracy : 0.565625   |  Another Accuracy : 1.710000\n",
      "  5/10 :  Train Loss : 0.658533  |  Test Loss : 0.656176  | Accuracy : 0.642708   |  Another Accuracy : 1.890000\n",
      "  6/10 :  Train Loss : 0.639802  |  Test Loss : 0.652499  | Accuracy : 0.638542   |  Another Accuracy : 1.910000\n",
      "  7/10 :  Train Loss : 0.633046  |  Test Loss : 0.683420  | Accuracy : 0.560417   |  Another Accuracy : 1.710000\n",
      "  8/10 :  Train Loss : 0.644767  |  Test Loss : 0.655320  | Accuracy : 0.573958   |  Another Accuracy : 1.670000\n",
      "  9/10 :  Train Loss : 0.619238  |  Test Loss : 0.656174  | Accuracy : 0.622917   |  Another Accuracy : 1.860000\n",
      " 10/10 :  Train Loss : 0.638407  |  Test Loss : 0.661428  | Accuracy : 0.617708   |  Another Accuracy : 1.860000\n"
     ]
    }
   ],
   "source": [
    "epochs, all_train_losses, all_test_losses, all_accuracies = 10, [], [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    losses_train, losses_test, accuracies_test, another_accuracy = 0, 0, 0, 0\n",
    "    for index_data, (features_train, target_train) in enumerate(iter(dataloader_train)):\n",
    "\n",
    "        features_train = features_train.to(device)\n",
    "        target_train = target_train.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        prediction_train = model.forward(features_train)\n",
    "        loss_train = criterion(prediction_train, target_train)\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses_train += loss_train.item()\n",
    "\n",
    "    average_losses_train = losses_train/len(dataloader_train)\n",
    "    all_train_losses.append(average_losses_train)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for index_data, (features_test, target_test) in enumerate(iter(dataloader_test)):\n",
    "\n",
    "            features_test = features_test.to(device)\n",
    "            target_test   = target_test.to(device)\n",
    "\n",
    "            prediction_test = model.forward(features_test)\n",
    "            loss_test = criterion(prediction_test, target_test)\n",
    "\n",
    "            losses_test += loss_test.item()\n",
    "\n",
    "            prediction_class = torch.argmax(prediction_test, dim=1)\n",
    "            accuracies_test += accuracy_score(prediction_class, target_test)\n",
    "\n",
    "            another_accuracy += (prediction_class == target_test).sum() / len(dataloader_test)         \n",
    "        average_another_loss = another_accuracy/len(dataloader_test)\n",
    "\n",
    "        average_losses_test = losses_test/len(dataloader_test)\n",
    "        all_test_losses.append(average_losses_test)\n",
    "\n",
    "        average_accuracy_test = accuracies_test/len(dataloader_test)\n",
    "        all_accuracies.append(average_accuracy_test)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    print(f'{epoch+1:3}/{epochs} :  Train Loss : {average_losses_train:.6f}  |  Test Loss : {average_losses_test:.6f}  | Accuracy : {average_accuracy_test:.6f}   |  Another Accuracy : {average_another_loss:.6f}')\n",
    "      "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\"model_state\": model.state_dict(), \"input_size\": 28*28}, 'new_trained_model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(all_train_losses, label='Training Losses')\n",
    "plt.plot(all_test_losses,  label='Testing Lossess')\n",
    "plt.plot(all_accuracies,   label='Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model = torch.load('new_trained_model')\n",
    "model_state = trained_model['model_state']\n",
    "\n",
    "model = CNN_Cat_and_Dog_Classification()\n",
    "model.load_state_dict(model_state)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image is a cat  [179.60070371627808]\n"
     ]
    }
   ],
   "source": [
    "# from tkinter import Image\n",
    "from PIL import ImageTk, Image\n",
    "\n",
    "preprocessor  = transforms.Compose([ transforms.Grayscale(), \n",
    "                                        transforms.Resize((224, 224)), \n",
    "                                        transforms.ToTensor(), \n",
    "                                        transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "                                      ])\n",
    "\n",
    "image_path = \"C:/Users/zorve/OneDrive/Documents/github datasets/cat_vs_dog/test/cat/cat.4003.jpg\"\n",
    "\n",
    "image = Image.open(image_path)\n",
    "image = preprocessor(image)\n",
    "image = image.view(1, *image.shape)\n",
    "\n",
    "def get_prediction(image, model, classes_dict):\n",
    "     model.eval()\n",
    "     with torch.no_grad():\n",
    "          probs = torch.exp(model(image))\n",
    "          prob, pred = torch.max(probs, dim=1)\n",
    "          print(f'This image is a {classes_dict[pred.item()]}  [{prob.item() * 100}]')\n",
    "\n",
    "classes_dict = {0: 'cat', 1: 'dog'}\n",
    "\n",
    "get_prediction(image, model, classes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image is a dog  [244.95604038238525]\n"
     ]
    }
   ],
   "source": [
    "image_path = \"C:/Users/zorve/OneDrive/Documents/github datasets/cat_vs_dog/test/dog/dog.4025.jpg\"\n",
    "\n",
    "image = Image.open(image_path)\n",
    "image = preprocessor(image)\n",
    "image = image.view(1, *image.shape)\n",
    "\n",
    "def get_prediction(image, model, classes_dict):\n",
    "     model.eval()\n",
    "     with torch.no_grad():\n",
    "          probs = torch.exp(model(image))\n",
    "          prob, pred = torch.max(probs, dim=1)\n",
    "          print(f'This image is a {classes_dict[pred.item()]}  [{prob.item() * 100}]')\n",
    "\n",
    "classes_dict = {0: 'cat', 1: 'dog'}\n",
    "\n",
    "get_prediction(image, model, classes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predict(image_path, model):\n",
    "     preprocessor  = transforms.Compose([ transforms.Grayscale(), transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "                                      ])\n",
    "     classes_dict = {0: 'cat', 1: 'dog'}\n",
    "\n",
    "     image = Image.open(image_path)\n",
    "     processed_image = preprocessor(image)\n",
    "     processed_image = processed_image.view(1, *processed_image.shape)\n",
    "\n",
    "     model.eval()\n",
    "     with torch.no_grad():\n",
    "          prediction = model.forward(processed_image)\n",
    "          _, prediction_class = torch.max(prediction, dim=1)\n",
    "\n",
    "     plt.imshow(image, cmap='gray')\n",
    "     plt.title(f'Prediction digit:  {prediction_class.item()}    ({classes_dict[prediction_class.item()]})', fontsize=15)\n",
    "     plt.show()\n",
    "\n",
    "     return\n",
    "\n",
    "from PIL import ImageTk, Image\n",
    "\n",
    "root_path = \"C:/Users/zorve/OneDrive/Documents/github datasets/cat_vs_dog/check/img_\"\n",
    "\n",
    "for i in range(0, 11, 1):\n",
    "     image_path_arg = root_path +  str(i) + \".jpg\"\n",
    "     image_path = image_path_arg\n",
    "     make_predict(image_path, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
